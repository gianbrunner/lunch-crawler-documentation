\chapter{Stand der Forschung}
Diese Arbeit stützt sich auf verschiedene Bücher, Websites und Artikel.
Die Grundlagen eines Webcrawlers wurden mit Hilfe des Buchs \glqq Web Data Mining\grqq{} Kapitel 8 erkannt. %Referenz Bing Liu
Darin wird die Vorgehensweise eines Webcrawlers erläutert und zudem diverse bekannte Implementierungsprobleme.
Die Umsetzung mit Stormcrawler SDK wurde hauptsächlich durch das Wiki des Erstellers, Julien Nioche, erarbeitet. % Referenz https://github.com/DigitalPebble/storm-crawler/wiki
Da Stormcrawler auf Apache Storm basiert, wurden die Prinzipien dieser Technologie durch den Artikel "Playing with Apache Storm on Docker - Like a Boss" gelernt. % https://dev.to/usamaashraf/playing-with-apache-storm-on-docker---like-a-boss-4bgb
Die Klassifizierung der Webpages erforderte grundlegende Kenntnisse in der Datenverarbeitung und Machine Learning.
Diese Kenntisse wurden im Modul \glqq Machine Learning\grqq{} von Christoph Würsch unterrichtet. % Referenz auf Würsch???
% Elasticsearch

