\chapter{Stand der Forschung}
Diese Arbeit stützt sich auf verschiedene Bücher, Websites und Artikel.
Die Grundlagen eines Webcrawlers wurden mit Hilfe des Buchs \glqq Web Data Mining\grqq{} Kapitel 8 erkannt \cite{liu2007web}. 
Darin wird die Vorgehensweise eines Webcrawlers erläutert und zudem diverse bekannte Implementierungsprobleme.
Die Umsetzung mit Stormcrawler SDK wurde hauptsächlich durch die Website und das Wiki des Erstellers, Julien Nioche, erarbeitet \cite{StormCrawler} \cite{GithubStormCrawler}.
Da Stormcrawler auf Apache Storm basiert, wurden die Prinzipien dieser Technologie durch den Artikel "Playing with Apache Storm on Docker - Like a Boss" gelernt \cite{ApacheStormDev}.
Die Klassifizierung der Webpages erforderte grundlegende Kenntnisse in der Datenverarbeitung und Machine Learning.
Diese Kenntisse wurden im Modul \glqq Machine Learning\grqq{} von Christoph Würsch unterrichtet. % Referenz auf Würsch???
% Elasticsearch

