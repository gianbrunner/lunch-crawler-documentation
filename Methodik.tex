\chapter{Methodik}
\section{Forschungsfrage}
Die Forschungsfrage, welcher mit dieser Arbeit beantwortet wird, lautet wie folgt:\\

\emph{Können Webpages von Restaurant-Websites mit hoher Erfolgschance klassifiziert werden, ob sie Menüinformationen beinhalten?}\\

Als hohe Erfolgschance sind Werte für die Metriken \glqq F1-Score\grqq{} sowie \glqq Precision\grqq{} von mindestens 0.8 definiert.
Es handelt sich um eine binäre Klassifikation, also eine Einteilung in zwei Kategorien, nämlich \glqq Menüseite\grqq{} oder \glqq Keine Menüseite\grqq.
Folgende Einschränkungen werden vorgegeben, um diese Frage beantworten zu können:
\begin{itemize}
	\item Die Webpages sind ausschliesslich von Restaurant-Websites
	\item Die Sprache der Webpages ist deutsch
\end{itemize}
\section{Ergebnisse der Klassifizierung}
In diesem Abschnitt wird zwischen zwei verschiedenen Ansätzen, namentlich dem regelbasierten und dem Klassifizieren mittels Machine-Learning unterschieden.
\subsection{Regelbasiertes Klassifizieren}
Die fünf verschiedenen Methoden des regelbasierten Klassifizierens haben folgende Ergebnisse erzielt:\\
\begin{table}[H]
\caption{Beste Scores der regelbasierten Klassifikation}
\centering
\begin{tabular}{|l|l|l|l|}
	\hline
	Methode & F1-Score & Precision & Recall\\
	\hline
	Menü im Titel & 0.17 & 0.43 & 0.11 \\
	Preisdetektor & 0.46 & 0.45 & 0.47 \\
	Kombination aus Menü im Titel und Preisdetektor & 0.47 & 0.43 & 0.52\\
	Listing & 0.55 & 0.60 & 0.50\\
	Bag of Words & 0.72 & 0.81 & 0.64\\
	\hline
\end{tabular}
\end{table}

Hinweis: Wenn mehrere Parameterkombinationen denselben F1-Score erreicht haben, ist diejenige mit der höheren Precision bevorzugt worden.
Die Klassifizierung in absoluten Zahlen wird mittels Konfusionsmatrix verdeutlicht.
\begin{table}[H]
	\caption{Konfusionsmatrix des Regelsets: Menü im Titel}
	\centering
\begin{tabular}{@{}cc|cc@{}}
	\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{Predicted} \\ 
	\multicolumn{1}{c}{} & 
	\multicolumn{1}{c|}{} & 
	\multicolumn{1}{c}{Positiv} & 
	\multicolumn{1}{c}{Negativ} \\ 
	\cline{2-4}
	\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{Actual}}
	& Positiv  & 64   & 542   \\[1.5ex]
	& Negativ  & 84   & 6173 \\ 
	\cline{2-4}
\end{tabular}
\end{table}

\begin{table}[H]
	\caption{Konfusionsmatrix des Regelsets: Preisdetektor}
	\centering
	\begin{tabular}{@{}cc|cc@{}}
		\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{Predicted} \\ 
		\multicolumn{1}{c}{} & 
		\multicolumn{1}{c|}{} & 
		\multicolumn{1}{c}{Positiv} & 
		\multicolumn{1}{c}{Negativ} \\ 
		\cline{2-4}
		\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{Actual}}
		& Positiv  & 284   & 322   \\[1.5ex]
		& Negativ  & 344   & 5913 \\ 
		\cline{2-4}
	\end{tabular}
\end{table}

\begin{table}[H]
	\caption{Konfusionsmatrix des Regelsets: Kombination aus Menü im Titel und Preisdetektor}
	\centering
	\begin{tabular}{@{}cc|cc@{}}
		\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{Predicted} \\ 
		\multicolumn{1}{c}{} & 
		\multicolumn{1}{c|}{} & 
		\multicolumn{1}{c}{Positiv} & 
		\multicolumn{1}{c}{Negativ} \\ 
		\cline{2-4}
		\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{Actual}}
		& Positiv  & 316   & 290   \\[1.5ex]
		& Negativ  & 426   & 5831 \\ 
		\cline{2-4}
	\end{tabular}
\end{table}

\begin{table}[H]
	\caption{Konfusionsmatrix des Regelsets: Listing}
	\centering
	\begin{tabular}{@{}cc|cc@{}}
		\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{Predicted} \\ 
		\multicolumn{1}{c}{} & 
		\multicolumn{1}{c|}{} & 
		\multicolumn{1}{c}{Positiv} & 
		\multicolumn{1}{c}{Negativ} \\ 
		\cline{2-4}
		\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{Actual}}
		& Positiv  & 305   & 200   \\[1.5ex]
		& Negativ  & 301   & 6057 \\ 
		\cline{2-4}
	\end{tabular}
\end{table}

\begin{table}[H]
	\caption{Konfusionsmatrix des Regelsets: Bag of Words}
	\centering
	\begin{tabular}{@{}cc|cc@{}}
		\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{Predicted} \\ 
		\multicolumn{1}{c}{} & 
		\multicolumn{1}{c|}{} & 
		\multicolumn{1}{c}{Positiv} & 
		\multicolumn{1}{c}{Negativ} \\ 
		\cline{2-4}
		\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{Actual}}
		& Positiv  & 108   & 25   \\[1.5ex]
		& Negativ  & 61   & 1865 \\ 
		\cline{2-4}
	\end{tabular}
\end{table}

\subsection{Klassifizieren mittels Machine-Learning Algorithmen}
Beim Machine-Learning Ansatz wurden für die drei Feature-Extraction Methoden \glqq Bag of Words mit Worthäufigkeit\grqq{}, \glqq Bag of Words ohne Worthäufigkeit (binär)\grqq{} und \glqq TF-IDF\grqq{}
jeweils 14 Algorithmen ausgetestet und stetig verbessert.
Danach wurde für jede Feature-Extraction Methode der Algorithmus mit dem besten F1-Score, sowie der besten Precision, kreuzvalidiert und nach den passendsten Hyperparametern gesucht.
Schlussendlich wurde der Algorithmus mit dem besten F1-Score und derjenige mit der besten Precision mit dem separaten Testset getestet und die finalen Scores, sowie die Konfusionsmatrix erstellt.
\\\\
Hinweis: Bei manchen Algorithmen wurden bei der Hyperparametersuche keine besseren Parameter gefunden.
In diesem Falle wurden die Standardparameter weiter verwendet.

\begin{table}[H]
	\caption{Beste Scores der Machine-Learning Klassifikation}
	\centering
	\begin{tabular}{|l|l|l|l|}
		\hline
		Methode & F1-Score & Precision & Recall\\
		\hline
		Perceptron mit binärem Bag of Words & 0.78 & 0.92 & 0.68 \\
		RandomForest mit binärem Bag of Words & 0.51 & 1.00 & 0.34 \\
		\hline
	\end{tabular}
\end{table}

\begin{table}[H]
	\caption{Konfusionsmatrix der Methode: Perceptron mit binärem Bag of Words}
	\centering
	\begin{tabular}{@{}cc|cc@{}}
		\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{Predicted} \\ 
		\multicolumn{1}{c}{} & 
		\multicolumn{1}{c|}{} & 
		\multicolumn{1}{c}{Positiv} & 
		\multicolumn{1}{c}{Negativ} \\ 
		\cline{2-4}
		\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{Actual}}
		& Positiv  & 34   & 3   \\[1.5ex]
		& Negativ  & 16   & 47 \\ 
		\cline{2-4}
	\end{tabular}
\end{table}

\begin{table}[H]
	\caption{Konfusionsmatrix der Methode: RandomForest mit binärem Bag of Words}
	\centering
	\begin{tabular}{@{}cc|cc@{}}
		\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{Predicted} \\ 
		\multicolumn{1}{c}{} & 
		\multicolumn{1}{c|}{} & 
		\multicolumn{1}{c}{Positiv} & 
		\multicolumn{1}{c}{Negativ} \\ 
		\cline{2-4}
		\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{Actual}}
		& Positiv  & 17   & 0   \\[1.5ex]
		& Negativ  & 33   & 50 \\ 
		\cline{2-4}
	\end{tabular}
\end{table}

\section{Interpretation der Ergebnisse}
\subsection{Regelbasiertes Klassifizieren}
Die verschiedenen Methoden ergeben stark unterschiedliche Werte.
Die simpelste Methode, das Überprüfen des Schlagworts \glqq menu\grqq{} im Titel hat ein sehr schlechtes Ergebnis geliefert. 
Nur 64, also ca. 11\% der Menüseiten wurden erkannt, dafür sind 84 Webpages als solche klassifiziert worden, welche gar keine sind.

Die Suche nach Preisen innerhalb des Textes hat ein etwas besseres Ergebnis geliefert, bereits 284, also ca. 57\% der Menüseiten sind gefunden worden. 
Jedoch sind auch 344 Webpages fälschlicherweise als Menüseiten klassifiziert worden, was kein deutlich besseres Verhältnis als bei ersterer Methode ergibt.

Eine Kombination dieser beiden Methoden ergibt ebenfalls keine markant besseren Werte.
316 oder ca. 52\% der Menüseiten wurden als solche erkannt, aber 426 Webpages wurden fälschlicherweise positiv klassifiziert.

Das Verwenden einer Blacklist und Whitelist wurden fast gleich viele Menüseiten korrekt erkannt. Bei 305, also ca. 50\% der erkannten Webseiten wurden 301  Webpages als Menüseiten klassifiziert, welche keine sind.
%Diese Zahlen würden sich verändern, wenn eine Änderung dieser Listen vorgenommen werden würden.
%Ob dies zu einer Verbesserung oder Verschlechterung führt, lässt sich nicht pauschal sagen.

Die Klassifikation mit der Methode \glqq Bag of Words\grqq{} führt zu den besten Ergebnissen der regelbasierten Klassifikation.
Dabei muss jedoch beachtet werden, dass ein Teil der Daten verwendet wird, um die dynamischen Listen zu erstellen.
Dies führt zu den folgenden Zahlen: 108 Webpages (ca. 81\%) wurden korrekt als Menüseiten klassifiziert.
Dabei wurden 61 Webpages fälschlicherweise klassifiziert.
Dadurch können die Werte nicht direkt mit denjenigen Methoden verglichen werden, welche den kompletten Datensatz klassifizieren. \\

Insgesamt ist zu erkennen, dass eine qualitativ und quantitativ hochwertige Klassifikation von Texten unter diesen Umständen nicht möglich ist.
In allen Fällen wurde eine grosse Anzahl Webpages fälschlicherweise positiv klassifiziert.
Wenn man dies nun auf den Anwendungsfall einer Suchmaschine überträgt, werden viele irrelevante Seiten angezeigt.
Andererseits werden in Ausnahme der Methode \glqq Bag of Words\grqq{} höchstens die Hälfte der tatsächlichen Menüseiten gefunden.
\subsection{Klassifizieren mittels Machine-Learning Algorithmen}
Beim Vergleich beider Klassifizierer ist ein grosser Unterschied beim Recall ersichtlich.
Interessant ist, dass beide Algorithmen ziemlich zuverlässige Precision-Werte erzielen konnten.\\
RandomForest erreicht mit seiner Precision von 1.00 den Maximalwert, hat aber extreme Einbussen beim Recall, was sich auf den F1-Score niederschlägt.\\
Perceptron erzielte beim Recall ein leichtes Defizit, aber die wichtigere Kategorie Precision erreichte mit 0.92 einen durchaus anwendbaren Score.
\\\\
Schlussendlich ist ersichtlich, dass die Variante mit dem Perceptron-Algorithmus eine qualitative und quantitative Klassifizierung von Menüseiten erzielen kann.
Der F1-Score liegt zwar leicht unter dem selbst definierten Schwellwert von 0.8, jedoch ist die Precision mit 0.92 weit darüber.\\
Der RandomForest-Algorithmus kann als Klassifizierer zwar qualitative, aber keineswegs quantitative Einschätzungen erzielen.
Mit einer Precision von 1.00 könnte der RandomForest-Algorithmus theoretisch weiter verwendet werden, um weitere Daten zu labeln und die Traininsmenge zu erhöhen.
Mit der grösseren Trainingsmenge könnten die Algorithmen ausführlicher trainiert werden und schlussendlich bessere Einschätzungen abgeben.
\\

Für den \glqq Use-Case\grqq{} einer Suchmaschine, ist es besser, wenn nicht möglichst viel gefunden wird, sondern dass das Gefundene effektiv korrekt ist.
Dennoch dürfen nicht nur eine Hand voll von Menüseiten gefunden werden, damit das Angebot nicht verkümmert.\\
Der Perceptron-Algorithmus bietet einen guten Kompromiss zwischen Precision und Recall und wird deshalb für die Suchmaschine verwendet.
Mit seiner Precision von 0.92 erreicht er bei 37 Vorhersagen nur drei falsche Einschätzungen.
Somit wäre in der Suchmaschine jeder 13te Vorschlag falsch, was vertretbar ist.
\section{Beantwortung der Forschungsfrage}
Die Antwort auf die Forschungsfrage lautet: Ja.\\ Webpages von Restaurant-Websites können mit einer hohen Erfolgschance klassifiziert werden, ob diese Menüinformationen beinhalten.\\
Jedoch kann die gewünschte Anforderung betreffend Qualität und Quantität dieser Klassifikation mit dem regelbasierten Ansatz nicht bewerkstelligt werden.
Diese Antwort gilt nur für den Ansatz des maschinellen Lernens.
