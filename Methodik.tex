\chapter{Methodik}
\label{chap:methodik}
\section{Forschungsfrage}
Die Forschungsfrage, welcher mit dieser Arbeit beantwortet wird, lautet wie folgt:\\

\emph{Können Webpages von Restaurant-Websites mit hoher Erfolgschance klassifiziert werden, ob sie Menüinformationen beinhalten?}\\

Als hohe Erfolgschance sind Werte für die Metriken \glqq F1-Score\grqq{} sowie \glqq Precision\grqq{} von mindestens 0.8 definiert.
Es handelt sich um eine binäre Klassifikation, also eine Einteilung in zwei Kategorien, nämlich \glqq Menüseite\grqq{} oder \glqq Keine Menüseite\grqq.
Folgende Einschränkungen werden vorgegeben, um diese Frage beantworten zu können:
\begin{itemize}
	\item Die Webpages sind ausschliesslich von Restaurant-Websites
	\item Die Sprache der Webpages ist deutsch
\end{itemize}
\section{Ergebnisse der Klassifizierung}
In diesem Abschnitt wird zwischen zwei verschiedenen Ansätzen, namentlich dem regelbasierten und dem Klassifizieren mittels Machine-Learning unterschieden.
\subsection{Regelbasiertes Klassifizieren}
Alle fünf Methoden der regelbasierten Klassifikation wurden in denjenigen Konfigurationen, welche die besten Ergebnisse lieferten, anhand des Testdatensets des Gold Standards geprüft.
Die folgenden Ergebnisse wurden erzielt:\\

\begin{table}[H]
	\caption{Beste Scores der regelbasierten Klassifikation anhand des Testsets}
	\centering
	\begin{tabular}{|l|l|l|l|}
		\hline
		Methode & F1-Score & Precision & Recall\\
		\hline
		Menü im Titel & 0.28 & 1.00 & 0.16 \\
		Preisdetektor & 0.65 & 0.93 & 0.50 \\
		Kombination aus Menü im Titel und Preisdetektor & 0.70 & 0.93 & 0.56\\
		Listing & 0.68 & 0.96 & 0.52\\
		Bag of Words & 0.74 & 0.91 & 0.62\\
		\hline
	\end{tabular}
\end{table}
\begin{table}[H]
	\caption{Beste Scores der regelbasierten Klassifikation anhand des Trainingssets}
	\label{tab:rulebased_train}
	\centering
	\begin{tabular}{|l|l|l|l|}
		\hline
		Methode & F1-Score & Precision & Recall\\
		\hline
		Menü im Titel & 0.17 & 0.43 & 0.11 \\
		Preisdetektor & 0.46 & 0.45 & 0.47 \\
		Kombination aus Menü im Titel und Preisdetektor & 0.47 & 0.43 & 0.52\\
		Listing & 0.55 & 0.60 & 0.50\\
		\hline
	\end{tabular}
\end{table}


Hinweis: Wenn mehrere Parameterkombinationen denselben F1-Score erreicht haben, ist diejenige mit der höheren Precision bevorzugt worden.\\
Die Klassifizierung in absoluten Zahlen wird mittels Konfusionsmatrix verdeutlicht.
\begin{table}[H]
	\caption{Konfusionsmatrix des Regelsets: Menü im Titel}
	\centering
\begin{tabular}{@{}cc|cc@{}}
	\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{Predicted} \\ 
	\multicolumn{1}{c}{} & 
	\multicolumn{1}{c|}{} & 
	\multicolumn{1}{c}{Positiv} & 
	\multicolumn{1}{c}{Negativ} \\ 
	\cline{2-4}
	\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{Actual}}
	& Positiv  & 8   & 42   \\[1.5ex]
	& Negativ  & 0   & 50 \\ 
	\cline{2-4}
\end{tabular}
\end{table}

\begin{table}[H]
	\caption{Konfusionsmatrix des Regelsets: Preisdetektor}
	\centering
	\begin{tabular}{@{}cc|cc@{}}
		\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{Predicted} \\ 
		\multicolumn{1}{c}{} & 
		\multicolumn{1}{c|}{} & 
		\multicolumn{1}{c}{Positiv} & 
		\multicolumn{1}{c}{Negativ} \\ 
		\cline{2-4}
		\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{Actual}}
		& Positiv  & 25   & 25   \\[1.5ex]
		& Negativ  & 2    & 48 \\ 
		\cline{2-4}
	\end{tabular}
\end{table}

\begin{table}[H]
	\caption{Konfusionsmatrix des Regelsets: Kombination aus Menü im Titel und Preisdetektor}
	\centering
	\begin{tabular}{@{}cc|cc@{}}
		\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{Predicted} \\ 
		\multicolumn{1}{c}{} & 
		\multicolumn{1}{c|}{} & 
		\multicolumn{1}{c}{Positiv} & 
		\multicolumn{1}{c}{Negativ} \\ 
		\cline{2-4}
		\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{Actual}}
		& Positiv  & 28   & 22   \\[1.5ex]
		& Negativ  & 2   & 48 \\ 
		\cline{2-4}
	\end{tabular}
\end{table}

\begin{table}[H]
	\caption{Konfusionsmatrix des Regelsets: Listing}
	\centering
	\begin{tabular}{@{}cc|cc@{}}
		\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{Predicted} \\ 
		\multicolumn{1}{c}{} & 
		\multicolumn{1}{c|}{} & 
		\multicolumn{1}{c}{Positiv} & 
		\multicolumn{1}{c}{Negativ} \\ 
		\cline{2-4}
		\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{Actual}}
		& Positiv  & 26   & 24   \\[1.5ex]
		& Negativ  & 1   & 49 \\ 
		\cline{2-4}
	\end{tabular}
\end{table}

\begin{table}[H]
	\caption{Konfusionsmatrix des Regelsets: Bag of Words}
	\centering
	\begin{tabular}{@{}cc|cc@{}}
		\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{Predicted} \\ 
		\multicolumn{1}{c}{} & 
		\multicolumn{1}{c|}{} & 
		\multicolumn{1}{c}{Positiv} & 
		\multicolumn{1}{c}{Negativ} \\ 
		\cline{2-4}
		\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{Actual}}
		& Positiv  & 31   & 19   \\[1.5ex]
		& Negativ  & 3   & 47 \\ 
		\cline{2-4}
	\end{tabular}
\end{table}

\subsection{Klassifizieren mittels Machine-Learning Algorithmen}
Beim Machine-Learning Ansatz wurden für die drei Feature-Extraction Methoden \glqq Bag of Words mit Worthäufigkeit\grqq{}, \glqq Bag of Words ohne Worthäufigkeit (binär)\grqq{} und \glqq TF-IDF\grqq{}
jeweils 14 Algorithmen ausgetestet und stetig verbessert.
Danach wurde für jede Feature-Extraction Methode der Algorithmus mit dem besten F1-Score, sowie der besten Precision, kreuzvalidiert und nach den passendsten Hyperparametern gesucht.
Schlussendlich wurde der Algorithmus mit dem besten F1-Score und derjenige mit der besten Precision mit dem separaten Testset getestet und die finalen Scores, sowie die Konfusionsmatrix erstellt.
\\\\
Hinweis: Bei manchen Algorithmen wurden bei der Hyperparametersuche keine besseren Parameter gefunden.
In diesem Falle wurden die Standardparameter weiter verwendet.

\begin{table}[H]
	\caption{Beste Scores der Machine-Learning Klassifikation}
	\centering
	\begin{tabular}{|l|l|l|l|}
		\hline
		Methode & F1-Score & Precision & Recall\\
		\hline
		Perceptron mit binärem Bag of Words & 0.78 & 0.92 & 0.68 \\
		RandomForest mit binärem Bag of Words & 0.51 & 1.00 & 0.34 \\
		\hline
	\end{tabular}
\end{table}

\begin{table}[H]
	\caption{Konfusionsmatrix der Methode: Perceptron mit binärem Bag of Words}
	\centering
	\begin{tabular}{@{}cc|cc@{}}
		\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{Predicted} \\ 
		\multicolumn{1}{c}{} & 
		\multicolumn{1}{c|}{} & 
		\multicolumn{1}{c}{Positiv} & 
		\multicolumn{1}{c}{Negativ} \\ 
		\cline{2-4}
		\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{Actual}}
		& Positiv  & 34   & 16   \\[1.5ex]
		& Negativ  & 3   & 47 \\ 
		\cline{2-4}
	\end{tabular}
\end{table}

\begin{table}[H]
	\caption{Konfusionsmatrix der Methode: RandomForest mit binärem Bag of Words}
	\centering
	\begin{tabular}{@{}cc|cc@{}}
		\multicolumn{1}{c}{} &\multicolumn{1}{c}{} &\multicolumn{2}{c}{Predicted} \\ 
		\multicolumn{1}{c}{} & 
		\multicolumn{1}{c|}{} & 
		\multicolumn{1}{c}{Positiv} & 
		\multicolumn{1}{c}{Negativ} \\ 
		\cline{2-4}
		\multirow[c]{2}{*}{\rotatebox[origin=tr]{90}{Actual}}
		& Positiv  & 17   & 33   \\[1.5ex]
		& Negativ  & 0   & 50 \\ 
		\cline{2-4}
	\end{tabular}
\end{table}

\section{Interpretation der Ergebnisse}
\subsection{Regelbasiertes Klassifizieren}
Die verschiedenen Methoden ergeben, abgesehen von der Methode \glqq Menü im Titel\grqq{}, ähnliche Ergebnisse.
Diese hat im Bezug auf den F1-Score das schlechteste Ergebnis geliefert, dafür einen Precision-Wert von 1, es ist also keine Webpage fälschlicherweise als Menüseite klassifiziert worden.
Dafür sind auch nur 16\% der Menüseiten erkannt worden.

Die Suche nach Preisen innerhalb des Textes hat ein besseres Ergebnis geliefert, 50\% der Menüseiten wurden als solche erkannt und zwei Webpages wurden fälschlicherweise als Menüseiten klassifiziert. 
Eine Kombination dieser beiden Methoden ergibt eine fast identische Klassifikation.
28 von 50 Menüseiten wurden erkannt, ebenfalls zwei wurden fälschlicherweise als Menüseiten klassifiziert.

Durch das Verwenden einer Blacklist und Whitelist wurden fast gleich viele Menüseiten korrekt erkannt. Bei 26, also ca. 52\% der erkannten Webseiten wurde 1 Webpages als Menüseiten klassifiziert, welche keine sind.

Die Klassifikation mit der Methode \glqq Bag of Words\grqq{} führt zu den besten Ergebnissen der regelbasierten Klassifikation.
31 von 50 Menüseiten wurden erkannt, zudem wurden 3 Webpages fälschlicherweise als Menüseiten klassifiziert.\\

Alle Methoden erreichten auf dem Testdatensatz eine genügend hohe Precision, jedoch ist der Recall jeweils so tief, dass der F1-Score nicht die vorausgesetzte Marke von 0.8 überschreitet.
Alle Methoden der regelbasierten Klassifikation mit Ausnahme der Methode \glqq Bag of Words\grqq{} funktionieren unabhängig vom Trainingsdatensatz.
Beim Evaluieren der besten Konfigurationsparameter wurden diese auf dem Trainingsdatensatz getestet.
Diese Ergebnisse sind in der Tabelle \cref{tab:rulebased_train} ersichtlich.
Im Vergleich zu den Ergebnissen des Testsets ist bei allen Regeln zu erkennen, dass die Werte deutlich tiefer sind.
Dadurch kann die Schlussfolgerung gezogen werden, dass mit einer steigender Anzahl zu klassifizierenden Daten die Diversität dieser steigt, was sich negativ auf die Ergebnisse auswirkt.
Insgesamt ist zu erkennen, dass eine qualitativ und quantitativ hochwertige Klassifikation von Webpagen vor allem mit steigender Datendiversität nicht möglich ist.
In allen Fällen wurde eine erhebliche Anzahl der Menüseiten nicht gefunden.
Wenn man dies nun auf den Anwendungsfall einer Suchmaschine überträgt, werden viele Menüseiten nicht angezeigt.
Im Bezug auf die Resultate des Trainingsdatensatzes ist zudem die Precision markant gesunken.
Dadurch werden im Anwendungsfall viele Webpages angezeigt, welche keine Menüseiten sind.
\subsection{Klassifizieren mittels Machine-Learning Algorithmen}
Beim Vergleich beider Klassifizierer ist ein grosser Unterschied beim Recall ersichtlich.
Interessant ist, dass beide Algorithmen ziemlich zuverlässige Precision-Werte erzielen konnten.\\
RandomForest erreicht mit seiner Precision von 1.00 den Maximalwert, hat aber extreme Einbussen beim Recall, was sich auf den F1-Score niederschlägt.\\
Perceptron erzielte beim Recall ein leichtes Defizit, aber die wichtigere Kategorie Precision erreichte mit 0.92 einen durchaus anwendbaren Score.
\\\\
Schlussendlich ist ersichtlich, dass die Variante mit dem Perceptron-Algorithmus eine qualitative und quantitative Klassifizierung von Menüseiten erzielen kann.
Der F1-Score liegt zwar leicht unter dem selbst definierten Schwellwert von 0.8, jedoch ist die Precision mit 0.92 weit darüber.\\
Der RandomForest-Algorithmus kann als Klassifizierer zwar qualitative, aber keineswegs quantitative Einschätzungen erzielen.
Mit einer Precision von 1.00 könnte der RandomForest-Algorithmus theoretisch weiter verwendet werden, um weitere Daten zu labeln und die Traininsmenge zu erhöhen.
Mit der grösseren Trainingsmenge könnten die Algorithmen ausführlicher trainiert werden und schlussendlich bessere Einschätzungen abgeben.
\\

Für den Anwendungsfall einer Suchmaschine ist es besser, wenn nicht möglichst viel gefunden wird, sondern dass das Gefundene effektiv korrekt ist.
Dennoch dürfen nicht nur eine Hand voll von Menüseiten gefunden werden, damit das Angebot nicht verkümmert.\\
Der Perceptron-Algorithmus bietet einen guten Kompromiss zwischen Precision und Recall und wird deshalb für die Suchmaschine verwendet.
Mit seiner Precision von 0.92 erreicht er bei 37 Vorhersagen nur drei falsche Einschätzungen.
Somit wäre in der Suchmaschine jeder 13. Vorschlag falsch, was vertretbar ist.
\section{Beantwortung der Forschungsfrage}
Die Antwort auf die Forschungsfrage lautet: Ja.\\ Webpages von Restaurant-Websites können mit einer hohen Erfolgschance klassifiziert werden, ob diese Menüinformationen beinhalten.\\
Jedoch kann die gewünschte Anforderung betreffend Qualität und Quantität dieser Klassifikation mit dem regelbasierten Ansatz nicht bewerkstelligt werden.
Diese Antwort gilt nur für den Ansatz des maschinellen Lernens.
